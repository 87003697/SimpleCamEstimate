#!/usr/bin/env python3
"""
å¿«é€ŸVGGTè°ƒè¯•æµ‹è¯•
"""

import numpy as np
import torch
import sys
import os
sys.path.append('.')

def test_vggt_inference():
    """å¿«é€Ÿæµ‹è¯•VGGTæ¨ç†"""
    print("ğŸ” å¿«é€ŸVGGTæ¨ç†æµ‹è¯•...")
    
    try:
        from camera_search.vggt_helper import VGGTHelper
        
        # åˆ›å»ºVGGTåŠ©æ‰‹
        helper = VGGTHelper(device="cuda")
        helper.load_model()
        
        if not helper.is_loaded:
            print("âŒ VGGTæ¨¡å‹åŠ è½½å¤±è´¥")
            return
            
        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        print("ğŸ“¸ åˆ›å»ºæµ‹è¯•å›¾åƒ...")
        reference_image = np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8)
        rendered_views = [
            np.random.randint(0, 255, (518, 518, 3), dtype=np.uint8),
            np.random.randint(0, 255, (500, 500, 3), dtype=np.uint8),
        ]
        
        print(f"   å‚è€ƒå›¾åƒå½¢çŠ¶: {reference_image.shape}")
        print(f"   æ¸²æŸ“è§†å›¾æ•°é‡: {len(rendered_views)}")
        for i, view in enumerate(rendered_views):
            print(f"   è§†å›¾{i}å½¢çŠ¶: {view.shape}")
        
        # æµ‹è¯•å›¾åƒé¢„å¤„ç†
        print("ğŸ”„ æµ‹è¯•å›¾åƒé¢„å¤„ç†...")
        all_images = [reference_image] + rendered_views
        try:
            images_tensor = helper._preprocess_images(all_images)
            print(f"   âœ… é¢„å¤„ç†æˆåŠŸï¼Œå¼ é‡å½¢çŠ¶: {images_tensor.shape}")
        except Exception as e:
            print(f"   âŒ é¢„å¤„ç†å¤±è´¥: {e}")
            return
        
        # æµ‹è¯•æ¨¡å‹æ¨ç†
        print("ğŸ¤– æµ‹è¯•æ¨¡å‹æ¨ç†...")
        try:
            with torch.no_grad():
                with torch.cuda.amp.autocast(dtype=helper.dtype):
                    predictions = helper.model(images_tensor)
            print(f"   âœ… æ¨¡å‹æ¨ç†æˆåŠŸ")
            print(f"   é¢„æµ‹ç»“æœé”®: {list(predictions.keys())}")
            
            # æ£€æŸ¥å„ä¸ªè¾“å‡ºçš„å½¢çŠ¶
            for key, value in predictions.items():
                if isinstance(value, torch.Tensor):
                    print(f"   {key}: {value.shape}")
                    
        except Exception as e:
            print(f"   âŒ æ¨¡å‹æ¨ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return
        
        # æµ‹è¯•ç‚¹äº‘æå–
        print("â˜ï¸ æµ‹è¯•ç‚¹äº‘æå–...")
        try:
            point_clouds = helper._extract_point_clouds(predictions, images_tensor)
            print(f"   âœ… ç‚¹äº‘æå–æˆåŠŸï¼Œæ•°é‡: {len(point_clouds)}")
            for i, pc in enumerate(point_clouds):
                print(f"   ç‚¹äº‘{i}å½¢çŠ¶: {pc.shape}")
        except Exception as e:
            print(f"   âŒ ç‚¹äº‘æå–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return
        
        # æµ‹è¯•å®Œæ•´æ¨ç†
        print("ğŸ¯ æµ‹è¯•å®Œæ•´æ¨ç†...")
        try:
            result = helper.inference(reference_image, rendered_views)
            print(f"   âœ… å®Œæ•´æ¨ç†æˆåŠŸ")
            print(f"   å‚è€ƒç‚¹äº‘å½¢çŠ¶: {result.reference_pc.shape}")
            print(f"   æ¸²æŸ“ç‚¹äº‘æ•°é‡: {len(result.rendered_pcs)}")
            print(f"   æ·±åº¦å›¾æ•°é‡: {len(result.depth_maps)}")
            print(f"   ç½®ä¿¡åº¦åˆ†æ•°: {result.confidence_scores}")
        except Exception as e:
            print(f"   âŒ å®Œæ•´æ¨ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return
            
        print("ğŸ‰ VGGTå¿«é€Ÿæµ‹è¯•å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_vggt_inference() 