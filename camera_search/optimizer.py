"""
ä¼˜åŒ–å™¨æ¨¡å—
åŒ…å«PSOå’Œæ¢¯åº¦ä¸‹é™ä¼˜åŒ–å™¨
"""

import torch
import random
from typing import List, Callable, Tuple, Dict, Any
from .core import CameraPose

class PSOOptimizer:
    """ç²’å­ç¾¤ä¼˜åŒ–å™¨"""
    
    def __init__(self, num_particles: int = 30, max_iterations: int = 50, 
                 w: float = 0.9, c1: float = 2.0, c2: float = 2.0):
        self.num_particles = num_particles
        self.max_iterations = max_iterations
        self.w = w  # æƒ¯æ€§æƒé‡
        self.c1 = c1  # ä¸ªä½“å­¦ä¹ å› å­
        self.c2 = c2  # ç¤¾ä¼šå­¦ä¹ å› å­
        
    def optimize(self, objective_func: Callable[[CameraPose], float], 
                candidates: List[CameraPose], 
                bounds: Dict[str, Tuple[float, float]]) -> CameraPose:
        """PSOä¼˜åŒ– - ä¼ ç»Ÿå•æ¬¡æ¸²æŸ“ç‰ˆæœ¬"""
        
        print(f"   ğŸŒ Using traditional PSO optimization ({self.num_particles} particles, {self.max_iterations} iterations)")
        
        # ä»å€™é€‰å§¿æ€ä¸­é€‰æ‹©åˆå§‹ç§ç¾¤
        if len(candidates) >= self.num_particles:
            particles = candidates[:self.num_particles]
        else:
            particles = candidates + self._generate_random_particles(
                self.num_particles - len(candidates), bounds)
        
        # åˆå§‹åŒ–é€Ÿåº¦å’Œä¸ªä½“æœ€ä¼˜
        velocities = [self._initialize_velocity() for _ in particles]
        personal_best = particles.copy()
        personal_best_scores = [objective_func(p) for p in personal_best]
        
        # å…¨å±€æœ€ä¼˜
        global_best_idx = torch.argmin(torch.tensor(personal_best_scores)).item()
        global_best = personal_best[global_best_idx]
        global_best_score = personal_best_scores[global_best_idx]
        
        print(f"   ğŸ“Š Initial best score: {global_best_score:.4f}")
        
        # è¿­ä»£ä¼˜åŒ–
        for iteration in range(self.max_iterations):
            for i in range(self.num_particles):
                # æ›´æ–°é€Ÿåº¦
                r1, r2 = torch.rand(2)
                
                # è®¡ç®—é€Ÿåº¦æ›´æ–°
                inertia = self._multiply_velocity(velocities[i], self.w)
                cognitive = self._multiply_velocity(
                    self._subtract_poses(personal_best[i], particles[i]), 
                    self.c1 * r1)
                social = self._multiply_velocity(
                    self._subtract_poses(global_best, particles[i]), 
                    self.c2 * r2)
                
                velocities[i] = self._add_velocities([inertia, cognitive, social])
                
                # æ›´æ–°ä½ç½®
                particles[i] = self._add_pose_velocity(particles[i], velocities[i])
                particles[i] = self._clamp_pose(particles[i], bounds)
                
                # è¯„ä¼°æ–°ä½ç½®
                score = objective_func(particles[i])
                
                # æ›´æ–°ä¸ªä½“æœ€ä¼˜
                if score < personal_best_scores[i]:
                    personal_best[i] = particles[i]
                    personal_best_scores[i] = score
                    
                    # æ›´æ–°å…¨å±€æœ€ä¼˜
                    if score < global_best_score:
                        global_best = particles[i]
                        global_best_score = score
            
            # è¿›åº¦æŠ¥å‘Š
            if (iteration + 1) % 5 == 0:
                print(f"   ğŸ“ˆ Iteration {iteration + 1}/{self.max_iterations}: best score = {global_best_score:.4f}")
        
        print(f"   âœ… Traditional PSO completed. Final best score: {global_best_score:.4f}")
        return global_best
    
    def optimize_batch(self, batch_objective_func: Callable[[List[CameraPose]], List[float]], 
                      candidates: List[CameraPose], 
                      bounds: Dict[str, Tuple[float, float]]) -> CameraPose:
        """PSOä¼˜åŒ– - æ‰¹é‡æ¸²æŸ“ç‰ˆæœ¬ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰"""
        
        print(f"   ğŸš€ Using batch PSO optimization ({self.num_particles} particles, {self.max_iterations} iterations)")
        
        # ä»å€™é€‰å§¿æ€ä¸­é€‰æ‹©åˆå§‹ç§ç¾¤
        if len(candidates) >= self.num_particles:
            particles = candidates[:self.num_particles]
        else:
            particles = candidates + self._generate_random_particles(
                self.num_particles - len(candidates), bounds)
        
        # åˆå§‹åŒ–é€Ÿåº¦å’Œä¸ªä½“æœ€ä¼˜
        velocities = [self._initialize_velocity() for _ in particles]
        personal_best = particles.copy()
        
        # æ‰¹é‡è¯„ä¼°åˆå§‹ç²’å­
        personal_best_scores = batch_objective_func(personal_best)
        
        # å…¨å±€æœ€ä¼˜
        global_best_idx = torch.argmin(torch.tensor(personal_best_scores)).item()
        global_best = personal_best[global_best_idx]
        global_best_score = personal_best_scores[global_best_idx]
        
        print(f"   ğŸ“Š Initial best score: {global_best_score:.4f}")
        
        # è¿­ä»£ä¼˜åŒ–
        for iteration in range(self.max_iterations):
            # æ›´æ–°æ‰€æœ‰ç²’å­çš„é€Ÿåº¦å’Œä½ç½®
            for i in range(self.num_particles):
                # æ›´æ–°é€Ÿåº¦
                r1, r2 = torch.rand(2)
                
                # è®¡ç®—é€Ÿåº¦æ›´æ–°
                inertia = self._multiply_velocity(velocities[i], self.w)
                cognitive = self._multiply_velocity(
                    self._subtract_poses(personal_best[i], particles[i]), 
                    self.c1 * r1)
                social = self._multiply_velocity(
                    self._subtract_poses(global_best, particles[i]), 
                    self.c2 * r2)
                
                velocities[i] = self._add_velocities([inertia, cognitive, social])
                
                # æ›´æ–°ä½ç½®
                particles[i] = self._add_pose_velocity(particles[i], velocities[i])
                particles[i] = self._clamp_pose(particles[i], bounds)
            
            # å…³é”®ä¼˜åŒ–ï¼šæ‰¹é‡è¯„ä¼°æ‰€æœ‰ç²’å­
            current_scores = batch_objective_func(particles)
            
            # æ›´æ–°ä¸ªä½“æœ€ä¼˜å’Œå…¨å±€æœ€ä¼˜
            for i, score in enumerate(current_scores):
                if score < personal_best_scores[i]:
                    personal_best[i] = particles[i]
                    personal_best_scores[i] = score
                    
                    # æ›´æ–°å…¨å±€æœ€ä¼˜
                    if score < global_best_score:
                        global_best = particles[i]
                        global_best_score = score
            
            # è¿›åº¦æŠ¥å‘Š
            if (iteration + 1) % 5 == 0:
                print(f"   ğŸ“ˆ Iteration {iteration + 1}/{self.max_iterations}: best score = {global_best_score:.4f}")
        
        print(f"   âœ… PSO completed. Final best score: {global_best_score:.4f}")
        return global_best

    def _generate_random_particles(self, num: int, bounds: Dict[str, Tuple[float, float]]) -> List[CameraPose]:
        """ç”Ÿæˆéšæœºç²’å­"""
        particles = []
        for _ in range(num):
            pose = CameraPose(
                elevation=torch.rand(1).item() * (bounds['elevation'][1] - bounds['elevation'][0]) + bounds['elevation'][0],
                azimuth=torch.rand(1).item() * (bounds['azimuth'][1] - bounds['azimuth'][0]) + bounds['azimuth'][0],
                radius=torch.rand(1).item() * (bounds['radius'][1] - bounds['radius'][0]) + bounds['radius'][0]
            )
            particles.append(pose)
        return particles
    
    def _initialize_velocity(self) -> Dict[str, float]:
        """åˆå§‹åŒ–é€Ÿåº¦"""
        return {
            'elevation': torch.randn(1).item() * 2.0,
            'azimuth': torch.randn(1).item() * 5.0,
            'radius': torch.randn(1).item() * 0.5
        }
    
    def _multiply_velocity(self, velocity: Dict[str, float], factor: float) -> Dict[str, float]:
        """é€Ÿåº¦ä¹˜ä»¥å› å­"""
        return {k: v * factor for k, v in velocity.items()}
    
    def _subtract_poses(self, pose1: CameraPose, pose2: CameraPose) -> Dict[str, float]:
        """è®¡ç®—å§¿æ€å·®å¼‚ - æ­£ç¡®å¤„ç†æ–¹ä½è§’å‘¨æœŸæ€§"""
        
        # å¤„ç†ä»°è§’å’ŒåŠå¾„ - ç›´æ¥ç›¸å‡
        elevation_diff = pose1.elevation - pose2.elevation
        radius_diff = pose1.radius - pose2.radius
        
        # å¤„ç†æ–¹ä½è§’ - è€ƒè™‘å‘¨æœŸæ€§ï¼Œé€‰æ‹©æœ€çŸ­è·¯å¾„
        azimuth_diff = pose1.azimuth - pose2.azimuth
        
        # å°†å·®å¼‚é™åˆ¶åœ¨[-180, 180]èŒƒå›´å†…
        if azimuth_diff > 180:
            azimuth_diff -= 360
        elif azimuth_diff < -180:
            azimuth_diff += 360
        
        return {
            'elevation': elevation_diff,
            'azimuth': azimuth_diff,
            'radius': radius_diff
        }
    
    def _add_velocities(self, velocities: List[Dict[str, float]]) -> Dict[str, float]:
        """é€Ÿåº¦ç›¸åŠ """
        result = {'elevation': 0.0, 'azimuth': 0.0, 'radius': 0.0}
        for vel in velocities:
            for k in result:
                result[k] += vel[k]
        return result
    
    def _add_pose_velocity(self, pose: CameraPose, velocity: Dict[str, float]) -> CameraPose:
        """å§¿æ€åŠ é€Ÿåº¦"""
        return CameraPose(
            elevation=pose.elevation + velocity['elevation'],
            azimuth=pose.azimuth + velocity['azimuth'],
            radius=pose.radius + velocity['radius']
        )
    
    def _clamp_pose(self, pose: CameraPose, bounds: Dict[str, Tuple[float, float]]) -> CameraPose:
        """é™åˆ¶å§¿æ€èŒƒå›´ - æ­£ç¡®å¤„ç†æ–¹ä½è§’å‘¨æœŸæ€§"""
        
        # å¤„ç†ä»°è§’å’ŒåŠå¾„ - ä½¿ç”¨ç®€å•çš„æˆªæ–­
        elevation = max(bounds['elevation'][0], min(bounds['elevation'][1], pose.elevation))
        radius = max(bounds['radius'][0], min(bounds['radius'][1], pose.radius))
        
        # å¤„ç†æ–¹ä½è§’ - ä½¿ç”¨æ¨¡è¿ç®—å¤„ç†å‘¨æœŸæ€§
        azimuth = pose.azimuth % 360.0
        if azimuth < 0:
            azimuth += 360.0
        
        return CameraPose(
            elevation=elevation,
            azimuth=azimuth,
            radius=radius,
            center_x=pose.center_x,
            center_y=pose.center_y,
            center_z=pose.center_z
        )

class GradientDescentOptimizer:
    """æ¢¯åº¦ä¸‹é™ä¼˜åŒ–å™¨"""
    
    def __init__(self, learning_rate: float = 0.01, max_iterations: int = 100, 
                 tolerance: float = 1e-6):
        self.learning_rate = learning_rate
        self.max_iterations = max_iterations
        self.tolerance = tolerance
        
    def optimize(self, objective_func: Callable[[CameraPose], float], 
                initial_pose: CameraPose) -> CameraPose:
        """æ¢¯åº¦ä¸‹é™ä¼˜åŒ– - ä¼ ç»Ÿå•æ¬¡æ¸²æŸ“ç‰ˆæœ¬"""
        
        print(f"   ğŸŒ Using traditional gradient descent optimization (max {self.max_iterations} iterations)")
        
        current_pose = initial_pose
        
        for iteration in range(self.max_iterations):
            # è®¡ç®—æ¢¯åº¦
            gradient = self._compute_gradient(objective_func, current_pose)
            
            # è®¡ç®—æ¢¯åº¦èŒƒæ•°
            grad_norm = torch.sqrt(torch.tensor(gradient['elevation']**2 + 
                                              gradient['azimuth']**2 + 
                                              gradient['radius']**2))
            
            # æ£€æŸ¥æ”¶æ•›
            if grad_norm < self.tolerance:
                print(f"   âœ… Traditional gradient descent converged at iteration {iteration + 1} (grad_norm: {grad_norm:.6f})")
                break
                
            # æ›´æ–°å‚æ•°
            current_pose = CameraPose(
                elevation=current_pose.elevation - self.learning_rate * gradient['elevation'],
                azimuth=current_pose.azimuth - self.learning_rate * gradient['azimuth'],
                radius=current_pose.radius - self.learning_rate * gradient['radius']
            )
            
            # è¿›åº¦æŠ¥å‘Š
            if (iteration + 1) % 50 == 0:
                print(f"   ğŸ“Š Iteration {iteration + 1}/{self.max_iterations}: grad_norm = {grad_norm:.6f}")
        
        return current_pose
    
    def optimize_batch(self, batch_objective_func: Callable[[List[CameraPose]], List[float]], 
                      initial_pose: CameraPose) -> CameraPose:
        """æ¢¯åº¦ä¸‹é™ä¼˜åŒ– - æ‰¹é‡æ¸²æŸ“ç‰ˆæœ¬ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰"""
        
        print(f"   ğŸ¯ Using batch gradient descent optimization (max {self.max_iterations} iterations)")
        
        current_pose = initial_pose
        
        for iteration in range(self.max_iterations):
            # æ‰¹é‡è®¡ç®—æ¢¯åº¦
            gradient = self._compute_gradient_batch(batch_objective_func, current_pose)
            
            # è®¡ç®—æ¢¯åº¦èŒƒæ•°
            grad_norm = torch.sqrt(torch.tensor(gradient['elevation']**2 + 
                                              gradient['azimuth']**2 + 
                                              gradient['radius']**2))
            
            # æ£€æŸ¥æ”¶æ•›
            if grad_norm < self.tolerance:
                print(f"   âœ… Gradient descent converged at iteration {iteration + 1} (grad_norm: {grad_norm:.6f})")
                break
                
            # æ›´æ–°å‚æ•°
            current_pose = CameraPose(
                elevation=current_pose.elevation - self.learning_rate * gradient['elevation'],
                azimuth=current_pose.azimuth - self.learning_rate * gradient['azimuth'],
                radius=current_pose.radius - self.learning_rate * gradient['radius']
            )
            
            # è¿›åº¦æŠ¥å‘Š
            if (iteration + 1) % 50 == 0:
                print(f"   ğŸ“Š Iteration {iteration + 1}/{self.max_iterations}: grad_norm = {grad_norm:.6f}")
        
        return current_pose
    
    def _compute_gradient(self, objective_func: Callable[[CameraPose], float], 
                         pose: CameraPose) -> Dict[str, float]:
        """æ•°å€¼æ¢¯åº¦è®¡ç®— - ä¼ ç»Ÿå•æ¬¡æ¸²æŸ“ç‰ˆæœ¬"""
        epsilon = 1e-5
        
        # åŸºå‡†åˆ†æ•°
        base_score = objective_func(pose)
        
        # è®¡ç®—å„å‚æ•°çš„æ¢¯åº¦
        gradients = {}
        
        # elevationæ¢¯åº¦
        pose_plus = CameraPose(pose.elevation + epsilon, pose.azimuth, pose.radius)
        gradients['elevation'] = (objective_func(pose_plus) - base_score) / epsilon
        
        # azimuthæ¢¯åº¦
        pose_plus = CameraPose(pose.elevation, pose.azimuth + epsilon, pose.radius)
        gradients['azimuth'] = (objective_func(pose_plus) - base_score) / epsilon
        
        # radiusæ¢¯åº¦
        pose_plus = CameraPose(pose.elevation, pose.azimuth, pose.radius + epsilon)
        gradients['radius'] = (objective_func(pose_plus) - base_score) / epsilon
        
        return gradients
    
    def _compute_gradient_batch(self, batch_objective_func: Callable[[List[CameraPose]], List[float]], 
                               pose: CameraPose) -> Dict[str, float]:
        """æ•°å€¼æ¢¯åº¦è®¡ç®— - æ‰¹é‡æ¸²æŸ“ç‰ˆæœ¬ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰"""
        epsilon = 1e-5
        
        # æ„é€ æ‰°åŠ¨å§¿æ€ï¼š[åŸå§‹, +Îµ_elev, +Îµ_azim, +Îµ_radius]
        poses = [
            pose,  # åŸºå‡†
            CameraPose(pose.elevation + epsilon, pose.azimuth, pose.radius, 
                      pose.center_x, pose.center_y, pose.center_z),
            CameraPose(pose.elevation, pose.azimuth + epsilon, pose.radius,
                      pose.center_x, pose.center_y, pose.center_z),
            CameraPose(pose.elevation, pose.azimuth, pose.radius + epsilon,
                      pose.center_x, pose.center_y, pose.center_z)
        ]
        
        # æ‰¹é‡æ¸²æŸ“è¯„ä¼°
        scores = batch_objective_func(poses)
        base_score = scores[0]
        
        # è®¡ç®—æ¢¯åº¦
        gradients = {
            'elevation': (scores[1] - base_score) / epsilon,
            'azimuth': (scores[2] - base_score) / epsilon,
            'radius': (scores[3] - base_score) / epsilon
        }
        
        return gradients

class OptimizerManager:
    """ä¼˜åŒ–å™¨ç®¡ç†å™¨"""
    
    def __init__(self, pso_params: Dict[str, Any] = None, 
                 gd_params: Dict[str, Any] = None):
        
        # PSOå‚æ•°
        pso_defaults = {
            'num_particles': 30,
            'max_iterations': 50,
            'w': 0.9,
            'c1': 2.0,
            'c2': 2.0
        }
        pso_config = {**pso_defaults, **(pso_params or {})}
        self.pso = PSOOptimizer(**pso_config)
        
        # æ¢¯åº¦ä¸‹é™å‚æ•°  
        gd_defaults = {
            'learning_rate': 0.01,
            'max_iterations': 100,
            'tolerance': 1e-6
        }
        gd_config = {**gd_defaults, **(gd_params or {})}
        self.gd = GradientDescentOptimizer(**gd_config)
    
    def pso_optimize(self, objective_func: Callable[[CameraPose], float], 
                    candidates: List[CameraPose], 
                    bounds: Dict[str, Tuple[float, float]]) -> CameraPose:
        """PSOä¼˜åŒ– - ä¼ ç»Ÿå•æ¬¡æ¸²æŸ“ç‰ˆæœ¬"""
        return self.pso.optimize(objective_func, candidates, bounds)
    
    def pso_optimize_batch(self, batch_objective_func: Callable[[List[CameraPose]], List[float]], 
                          candidates: List[CameraPose], 
                          bounds: Dict[str, Tuple[float, float]]) -> CameraPose:
        """PSOä¼˜åŒ– - æ‰¹é‡æ¸²æŸ“ç‰ˆæœ¬ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰"""
        return self.pso.optimize_batch(batch_objective_func, candidates, bounds)
    
    def gradient_descent(self, objective_func: Callable[[CameraPose], float], 
                        initial_pose: CameraPose) -> CameraPose:
        """æ¢¯åº¦ä¸‹é™ä¼˜åŒ– - ä¼ ç»Ÿå•æ¬¡æ¸²æŸ“ç‰ˆæœ¬"""
        return self.gd.optimize(objective_func, initial_pose)
    
    def gradient_descent_batch(self, batch_objective_func: Callable[[List[CameraPose]], List[float]], 
                              initial_pose: CameraPose) -> CameraPose:
        """æ¢¯åº¦ä¸‹é™ä¼˜åŒ– - æ‰¹é‡æ¸²æŸ“ç‰ˆæœ¬ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰"""
        return self.gd.optimize_batch(batch_objective_func, initial_pose) 