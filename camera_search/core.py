"""
æ ¸å¿ƒV2M4ç›¸æœºæœç´¢ç®—æ³•å®ç°
åŒ…å«æ•°æ®ç»“æ„ã€å‡ ä½•å·¥å…·å’Œä¸»ç®—æ³•ç±»
"""

import os
import sys
import tempfile
import atexit
from dataclasses import dataclass
from typing import List, Optional, Tuple, Dict, Any
import numpy as np
import cv2
import trimesh
from pathlib import Path
from scipy.spatial.distance import cdist
import random

@dataclass
class CameraPose:
    """ç®€åŒ–çš„ç›¸æœºå§¿æ€å‚æ•° - ä¸KiuiKitå…¼å®¹"""
    elevation: float    # ä»°è§’ (åº¦)ï¼Œæ­£å€¼è¡¨ç¤ºç›¸æœºåœ¨ç‰©ä½“ä¸Šæ–¹  
    azimuth: float      # æ–¹ä½è§’ (åº¦)ï¼Œç»•å‚ç›´è½´æ—‹è½¬
    radius: float       # ç›¸æœºåˆ°ç›®æ ‡ç‚¹çš„è·ç¦»
    center_x: float = 0.0    # ç›®æ ‡ç‚¹xåæ ‡ (ç›¸æœºè§‚å¯Ÿçš„ä¸­å¿ƒç‚¹)
    center_y: float = 0.0    # ç›®æ ‡ç‚¹yåæ ‡
    center_z: float = 0.0    # ç›®æ ‡ç‚¹zåæ ‡
    
    @property
    def target_point(self) -> Tuple[float, float, float]:
        """è·å–ç›®æ ‡ç‚¹åæ ‡ï¼Œä¸kiui_mesh_renderer.pyå…¼å®¹"""
        return (self.center_x, self.center_y, self.center_z)
    
    def apply_to_kiui_camera(self, camera) -> None:
        """ç›´æ¥åº”ç”¨åˆ°KiuiKit OrbitCamera"""
        camera.from_angle(elevation=self.elevation, azimuth=self.azimuth, is_degree=True)
        camera.radius = self.radius
        camera.center = np.array([self.center_x, self.center_y, self.center_z], dtype=np.float32)
    
    def get_kiui_render_params(self) -> Dict[str, Any]:
        """è·å–kiui_mesh_renderer.render_single_view()çš„å‚æ•°"""
        return {
            'elevation': self.elevation,
            'azimuth': self.azimuth, 
            'distance': self.radius,
            'target_point': self.target_point
        }
    
    def to_matrix(self) -> np.ndarray:
        """è½¬æ¢ä¸º4x4å˜æ¢çŸ©é˜µ"""
        # çƒåæ ‡åˆ°ç¬›å¡å°”åæ ‡
        elev_rad = np.radians(self.elevation)
        azim_rad = np.radians(self.azimuth)
        
        x = self.radius * np.cos(elev_rad) * np.cos(azim_rad)
        y = self.radius * np.cos(elev_rad) * np.sin(azim_rad)
        z = self.radius * np.sin(elev_rad)
        
        # æ„é€ è§†å›¾çŸ©é˜µ
        camera_pos = np.array([x, y, z])
        target = np.array([self.center_x, self.center_y, self.center_z])
        up = np.array([0, 0, 1])
        
        # Look-atçŸ©é˜µ
        forward = target - camera_pos
        forward = forward / (np.linalg.norm(forward) + 1e-8)
        
        right = np.cross(forward, up)
        right = right / (np.linalg.norm(right) + 1e-8)
        
        up = np.cross(right, forward)
        
        view_matrix = np.eye(4)
        view_matrix[:3, 0] = right
        view_matrix[:3, 1] = up
        view_matrix[:3, 2] = -forward
        view_matrix[:3, 3] = camera_pos
        
        return view_matrix.astype(np.float32)
    
    def __str__(self) -> str:
        return f"CameraPose(elev={self.elevation:.1f}Â°, azim={self.azimuth:.1f}Â°, r={self.radius:.2f}, center=({self.center_x:.2f}, {self.center_y:.2f}, {self.center_z:.2f}))"

@dataclass
class DataPair:
    """æ•°æ®å¯¹ç»“æ„ - é€‚é…ç®€åŒ–çš„æ•°æ®æ ¼å¼"""
    scene_name: str              # åœºæ™¯åç§°
    mesh_path: str              # Meshæ–‡ä»¶è·¯å¾„: data/meshes/{scene_name}_textured_frame_000000.glb
    image_path: str             # å›¾åƒæ–‡ä»¶è·¯å¾„: data/images/{scene_name}.png
    
    @classmethod
    def from_scene_name(cls, scene_name: str, data_dir: str = "data"):
        """æ ¹æ®åœºæ™¯åç§°åˆ›å»ºæ•°æ®å¯¹"""
        mesh_path = f"{data_dir}/meshes/{scene_name}_textured_frame_000000.glb"
        image_path = f"{data_dir}/images/{scene_name}.png"
        return cls(scene_name, mesh_path, image_path)
    
    def exists(self) -> bool:
        """æ£€æŸ¥æ•°æ®å¯¹æ˜¯å¦å­˜åœ¨"""
        return Path(self.mesh_path).exists() and Path(self.image_path).exists()
    
    def load_mesh(self) -> trimesh.Trimesh:
        """åŠ è½½meshå¯¹è±¡"""
        if not Path(self.mesh_path).exists():
            raise FileNotFoundError(f"Meshæ–‡ä»¶ä¸å­˜åœ¨: {self.mesh_path}")
        
        loaded = trimesh.load(self.mesh_path)
        
        # å¤„ç†GLBæ–‡ä»¶å¯èƒ½è¿”å›Sceneå¯¹è±¡çš„æƒ…å†µ
        if hasattr(loaded, 'geometry') and loaded.geometry:
            # Sceneå¯¹è±¡ï¼Œæå–ç¬¬ä¸€ä¸ªå‡ ä½•ä½“
            mesh_name = list(loaded.geometry.keys())[0]
            return loaded.geometry[mesh_name]
        elif hasattr(loaded, 'vertices'):
            # ç›´æ¥æ˜¯Meshå¯¹è±¡
            return loaded
        else:
            raise ValueError(f"æ— æ³•ä»æ–‡ä»¶ä¸­æå–mesh: {self.mesh_path}")

class DataManager:
    """æ•°æ®å‘ç°å’ŒéªŒè¯ç®¡ç†å™¨"""
    
    def __init__(self, data_dir: str = "data"):
        self.data_dir = Path(data_dir)
        self.meshes_dir = self.data_dir / "meshes"
        self.images_dir = self.data_dir / "images"
    
    def discover_data_pairs(self) -> List[DataPair]:
        """å‘ç°æ‰€æœ‰å¯ç”¨çš„æ•°æ®å¯¹"""
        data_pairs = []
        
        if not self.meshes_dir.exists() or not self.images_dir.exists():
            return data_pairs
        
        # ä»meshæ–‡ä»¶æ¨æ–­åœºæ™¯åç§°
        for mesh_file in self.meshes_dir.glob("*_textured_frame_000000.glb"):
            scene_name = mesh_file.stem.replace("_textured_frame_000000", "")
            data_pair = DataPair.from_scene_name(scene_name, str(self.data_dir))
            
            if data_pair.exists():
                data_pairs.append(data_pair)
        
        return data_pairs
    
    def validate_data_structure(self) -> Dict:
        """éªŒè¯æ•°æ®ç»“æ„"""
        validation = {
            'total_mesh_files': 0,
            'total_image_files': 0,
            'valid_data_pairs': 0,
            'data_completeness': 0.0,
            'missing_scenes': []
        }
        
        if self.meshes_dir.exists():
            validation['total_mesh_files'] = len(list(self.meshes_dir.glob("*.glb")))
        
        if self.images_dir.exists():
            validation['total_image_files'] = len(list(self.images_dir.glob("*.png")))
        
        data_pairs = self.discover_data_pairs()
        validation['valid_data_pairs'] = len(data_pairs)
        
        if validation['total_mesh_files'] > 0:
            validation['data_completeness'] = (validation['valid_data_pairs'] / validation['total_mesh_files']) * 100
        
        return validation

class GeometryUtils:
    """å‡ ä½•å·¥å…· - åªä¿ç•™æ ¸å¿ƒåŠŸèƒ½"""
    
    @staticmethod
    def sample_sphere_poses(num_samples: int) -> List[CameraPose]:
        """çƒé¢ç­‰é¢ç§¯é‡‡æ ·"""
        poses = []
        for _ in range(num_samples):
            # ç­‰é¢ç§¯é‡‡æ ·
            u, v = np.random.random(2)
            elevation = np.degrees(np.arcsin(2 * u - 1))  # [-90Â°, 90Â°]
            azimuth = 360 * v  # [0Â°, 360Â°]
            
            # è·ç¦»é‡‡æ · (å¹³æ–¹æ ¹åˆ†å¸ƒ)
            radius = 1.0 + 4.0 * np.sqrt(np.random.random())
            
            # è½»å¾®çš„ä¸­å¿ƒç‚¹éšæœºåŒ–
            center_x = np.random.uniform(-0.5, 0.5)
            center_y = np.random.uniform(-0.5, 0.5)
            center_z = np.random.uniform(-0.5, 0.5)
            
            poses.append(CameraPose(
                elevation=elevation,
                azimuth=azimuth,
                radius=radius,
                center_x=center_x,
                center_y=center_y,
                center_z=center_z
            ))
        
        return poses
    
    @staticmethod
    def align_pointclouds_simple(reference_pc: np.ndarray, 
                               rendered_pcs: List[np.ndarray],
                               poses: List[CameraPose]) -> Optional[CameraPose]:
        """ç®€åŒ–ç‚¹äº‘å¯¹é½"""
        if not rendered_pcs or not poses:
            return None
            
        best_pose = None
        best_score = float('inf')
        
        # é¢„å¤„ç†å‚è€ƒç‚¹äº‘
        ref_pc_clean = GeometryUtils._clean_pointcloud(reference_pc)
        if ref_pc_clean is None or len(ref_pc_clean) == 0:
            return poses[0] if poses else None
        
        for rendered_pc, pose in zip(rendered_pcs, poses):
            if rendered_pc is None:
                continue
                
            # æ¸…ç†æ¸²æŸ“ç‚¹äº‘
            rend_pc_clean = GeometryUtils._clean_pointcloud(rendered_pc)
            if rend_pc_clean is None or len(rend_pc_clean) == 0:
                continue
                
            # ç®€å•çš„Chamferè·ç¦»å¯¹é½
            score = GeometryUtils._chamfer_distance(ref_pc_clean, rend_pc_clean)
            if score < best_score:
                best_score = score
                best_pose = pose
        
        return best_pose if best_pose else (poses[0] if poses else None)
    
    @staticmethod
    def _clean_pointcloud(pc: np.ndarray) -> Optional[np.ndarray]:
        """æ¸…ç†ç‚¹äº‘æ•°æ®ï¼Œç¡®ä¿æ­£ç¡®çš„æ ¼å¼"""
        if pc is None:
            return None
            
        # ç¡®ä¿æ˜¯numpyæ•°ç»„
        if not isinstance(pc, np.ndarray):
            return None
        
        # å¤„ç†ä¸åŒçš„ç»´åº¦æƒ…å†µ
        if len(pc.shape) == 4:  # (1, H, W, 3)
            pc = pc[0]  # å»æ‰batchç»´åº¦
        
        if len(pc.shape) == 3:  # (H, W, 3)
            # é‡å¡‘ä¸º (H*W, 3)
            pc = pc.reshape(-1, 3)
        
        if len(pc.shape) != 2 or pc.shape[1] != 3:
            return None
        
        # ç§»é™¤æ— æ•ˆç‚¹ (NaN, infç­‰)
        valid_mask = np.isfinite(pc).all(axis=1)
        pc_clean = pc[valid_mask]
        
        if len(pc_clean) == 0:
            return None
            
        return pc_clean
    
    @staticmethod
    def _chamfer_distance(pc1: np.ndarray, pc2: np.ndarray) -> float:
        """Chamferè·ç¦»è®¡ç®—"""
        if pc1 is None or pc2 is None or len(pc1) == 0 or len(pc2) == 0:
            return float('inf')
        
        # ç¡®ä¿éƒ½æ˜¯2Dæ•°ç»„
        if len(pc1.shape) != 2 or len(pc2.shape) != 2:
            return float('inf')
        
        if pc1.shape[1] != 3 or pc2.shape[1] != 3:
            return float('inf')
        
        # é‡‡æ ·ä»¥æé«˜æ•ˆç‡
        if len(pc1) > 1000:
            indices = np.random.choice(len(pc1), 1000, replace=False)
            pc1 = pc1[indices]
        if len(pc2) > 1000:
            indices = np.random.choice(len(pc2), 1000, replace=False)
            pc2 = pc2[indices]
        
        # Chamferè·ç¦»
        try:
            dist_matrix = cdist(pc1, pc2)
            forward = np.mean(np.min(dist_matrix, axis=1))
            backward = np.mean(np.min(dist_matrix, axis=0))
            return forward + backward
        except Exception as e:
            print(f"Chamferè·ç¦»è®¡ç®—å¤±è´¥: {e}")
            return float('inf')

class MeshRenderer:
    """Meshæ¸²æŸ“å™¨ - åŸºäºStandardKiuiRenderer"""
    
    def __init__(self, device: str = "cuda"):
        self.device = device
        self._renderer = None
        self._cached_mesh_path = None
        self._mesh_loaded = False
        
        # æ£€æŸ¥ä¾èµ–
        self._check_dependencies()
    
    def _check_dependencies(self):
        """æ£€æŸ¥å¿…è¦çš„ä¾èµ–"""
        try:
            # æ£€æŸ¥KiuiKit
            from kiui.mesh import Mesh as KiuiMesh
            from kiui.cam import OrbitCamera
            self.kiui_available = True
        except ImportError:
            raise ImportError("KiuiKitä¸å¯ç”¨ï¼Œè¯·å®‰è£…kiuiåŒ…")
        
        try:
            # æ£€æŸ¥nvdiffrast
            import nvdiffrast.torch as dr
            self.nvdiffrast_available = True
        except ImportError:
            raise ImportError("nvdiffrastä¸å¯ç”¨ï¼Œè¯·å®‰è£…nvdiffraståŒ…")
        
        try:
            # æ£€æŸ¥StandardKiuiRenderer
            sys.path.append(str(Path(__file__).parent.parent / "_reference" / "MeshSeriesGen" / "tools" / "visualization"))
            from kiui_mesh_renderer import StandardKiuiRenderer
            self.renderer_available = True
        except ImportError:
            raise ImportError("StandardKiuiRendererä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥è·¯å¾„è®¾ç½®")
    
    @property
    def renderer(self):
        """å»¶è¿Ÿåˆå§‹åŒ–æ¸²æŸ“å™¨"""
        if self._renderer is None:
            from kiui_mesh_renderer import StandardKiuiRenderer
            self._renderer = StandardKiuiRenderer(
                width=512, 
                height=512, 
                background_color=(1.0, 1.0, 1.0),
                device=self.device
            )
        return self._renderer
    
    def prepare_mesh(self, mesh: trimesh.Trimesh) -> str:
        """å‡†å¤‡meshç”¨äºæ¸²æŸ“ - å¯¼å‡ºä¸ºä¸´æ—¶æ–‡ä»¶"""
        if self._cached_mesh_path is None:
            # åˆ›å»ºæŒä¹…çš„ä¸´æ—¶æ–‡ä»¶
            temp_fd, temp_path = tempfile.mkstemp(suffix='.obj', prefix='v2m4_mesh_')
            os.close(temp_fd)
            
            # å¯¼å‡ºmesh
            mesh.export(temp_path)
            self._cached_mesh_path = temp_path
            
            # æ³¨å†Œæ¸…ç†å‡½æ•°
            def cleanup_cached_mesh():
                if self._cached_mesh_path and os.path.exists(self._cached_mesh_path):
                    os.unlink(self._cached_mesh_path)
            atexit.register(cleanup_cached_mesh)
        
        return self._cached_mesh_path
    
    def load_mesh_to_renderer(self, mesh_path: str):
        """åŠ è½½meshåˆ°æ¸²æŸ“å™¨"""
        if not self._mesh_loaded or self.renderer.mesh_path_loaded != mesh_path:
            loaded_mesh = self.renderer.load_mesh(mesh_path)
            if loaded_mesh is None:
                raise RuntimeError(f"æ— æ³•åŠ è½½meshåˆ°æ¸²æŸ“å™¨: {mesh_path}")
            self._mesh_loaded = True
    
    def render_single_view(self, mesh: trimesh.Trimesh, pose: CameraPose) -> np.ndarray:
        """æ¸²æŸ“å•ä¸ªè§†å›¾"""
        # å‡†å¤‡mesh
        mesh_path = self.prepare_mesh(mesh)
        self.load_mesh_to_renderer(mesh_path)
        
        # æ¸²æŸ“
        rendered_img = self.renderer.render_single_view(
            elevation=pose.elevation,
            azimuth=pose.azimuth,
            distance=pose.radius,
            target_point=pose.target_point,
            render_mode='lambertian'
        )
        
        if rendered_img is None:
            raise RuntimeError(f"æ¸²æŸ“å¤±è´¥: {pose}")
        
        return rendered_img
    
    def render_batch_views(self, mesh: trimesh.Trimesh, poses: List[CameraPose]) -> List[np.ndarray]:
        """æ‰¹é‡æ¸²æŸ“å¤šä¸ªè§†å›¾"""
        # å‡†å¤‡mesh
        mesh_path = self.prepare_mesh(mesh)
        self.load_mesh_to_renderer(mesh_path)
        
        # å‡†å¤‡æ‰¹é‡æ¸²æŸ“å‚æ•°
        camera_params = []
        for pose in poses:
            camera_params.append({
                'elevation': pose.elevation,
                'azimuth': pose.azimuth,
                'distance': pose.radius,
                'target_point': pose.target_point
            })
        
        # æ‰§è¡Œæ‰¹é‡æ¸²æŸ“
        rendered_images = self.renderer.render_batch_views(
            camera_params=camera_params,
            render_mode='lambertian',
            max_batch_size=8
        )
        
        # æ£€æŸ¥ç»“æœ
        valid_images = []
        for i, img in enumerate(rendered_images):
            if img is None:
                raise RuntimeError(f"æ‰¹é‡æ¸²æŸ“å¤±è´¥: pose {i}")
            valid_images.append(img)
        
        return valid_images

class CleanV2M4CameraSearch:
    """ç®€åŒ–ç‰ˆV2M4ç›¸æœºæœç´¢ç®—æ³•"""
    
    def __init__(self, dust3r_model_path: str, device: str = "cuda", enable_visualization: bool = True):
        self.device = device
        self.dust3r_model_path = dust3r_model_path
        self.enable_visualization = enable_visualization
        
        # ç®€åŒ–é…ç½®ï¼šåªä¿ç•™æ ¸å¿ƒå‚æ•°
        self.config = {
            'initial_samples': 2000,      # åˆå§‹é‡‡æ ·æ•°
            'top_n': 7,                   # DUSt3Rå€™é€‰æ•°
            'pso_particles': 50,          # PSOç²’å­æ•°
            'pso_iterations': 20,         # PSOè¿­ä»£æ•°
            'grad_iterations': 100,       # æ¢¯åº¦ä¸‹é™è¿­ä»£æ•°
            'image_size': 512,            # å›¾åƒå°ºå¯¸
            'render_batch_size': 128       # æ‰¹é‡æ¸²æŸ“å¤§å° (å¯è°ƒæ•´ä»¥å¹³è¡¡é€Ÿåº¦å’Œå†…å­˜)
        }
        
        # å»¶è¿Ÿåˆå§‹åŒ–ç»„ä»¶
        self._dust3r_helper = None
        self._renderer = None
        self._optimizer = None
        self._visualizer = None
        
        # å¯è§†åŒ–æ•°æ®æ”¶é›†
        self.visualization_data = {
            'progression': [],
            'mesh_info': {},
            'algorithm_stats': {}
        }
    
    @property
    def dust3r_helper(self):
        """å»¶è¿Ÿåˆå§‹åŒ–DUSt3RåŠ©æ‰‹"""
        if self._dust3r_helper is None:
            from .dust3r_helper import DUSt3RHelper
            self._dust3r_helper = DUSt3RHelper(self.dust3r_model_path, self.device)
        return self._dust3r_helper
    
    @property
    def renderer(self):
        """å»¶è¿Ÿåˆå§‹åŒ–æ¸²æŸ“å™¨"""
        if self._renderer is None:
            self._renderer = MeshRenderer(self.device)
        return self._renderer
    
    @property
    def optimizer(self):
        """å»¶è¿Ÿåˆå§‹åŒ–ä¼˜åŒ–å™¨"""
        if self._optimizer is None:
            from .optimizer import PSO_GD_Optimizer
            self._optimizer = PSO_GD_Optimizer()
        return self._optimizer
    
    @property
    def visualizer(self):
        """å»¶è¿Ÿåˆå§‹åŒ–å¯è§†åŒ–å™¨"""
        if self._visualizer is None and self.enable_visualization:
            from .visualization import V2M4Visualizer
            self._visualizer = V2M4Visualizer()
        return self._visualizer
    
    def search_camera_pose(self, data_pair: DataPair, save_visualization: bool = True) -> CameraPose:
        """ä¸»ç®—æ³•å…¥å£ - V2M4çš„9ä¸ªæ ¸å¿ƒæ­¥éª¤"""
        
        import time
        start_time = time.time()
        
        print(f"ğŸ¬ å¼€å§‹V2M4ç›¸æœºæœç´¢ç®—æ³•...")
        print(f"   åœºæ™¯: {data_pair.scene_name}")
        print(f"   Mesh: {data_pair.mesh_path}")
        print(f"   å›¾åƒ: {data_pair.image_path}")
        
        # éªŒè¯æ•°æ®å­˜åœ¨
        if not data_pair.exists():
            raise FileNotFoundError(f"æ•°æ®å¯¹ä¸å®Œæ•´: {data_pair.scene_name}")
        
        # åŠ è½½æ•°æ®
        reference_image = self._load_image(data_pair.image_path)
        mesh = data_pair.load_mesh()
        
        # æ”¶é›†meshä¿¡æ¯ç”¨äºå¯è§†åŒ–
        if self.enable_visualization:
            bounds = mesh.bounds
            self.visualization_data['mesh_info'] = {
                'vertices_count': len(mesh.vertices),
                'faces_count': len(mesh.faces),
                'bounds': bounds.tolist(),
                'center': mesh.centroid.tolist(),
                'scale': float(np.linalg.norm(bounds[1] - bounds[0]))
            }
        
        # æ­¥éª¤1: é‡‡æ ·åˆå§‹ç›¸æœºpose
        print("ğŸ“ æ­¥éª¤1: çƒé¢é‡‡æ ·ç›¸æœºå§¿æ€...")
        initial_poses = self._sample_sphere_poses()
        
        # æ­¥éª¤2: æ¸²æŸ“å¹¶é€‰æ‹©top-n
        print("ğŸ¯ æ­¥éª¤2: é€‰æ‹©top-nå€™é€‰å§¿æ€...")
        top_poses = self._select_top_poses(mesh, reference_image, initial_poses)
        
        # å¯è§†åŒ–ï¼šè®°å½•top-1å§¿æ€
        if self.enable_visualization and top_poses:
            rendered_top1 = self.renderer.render_single_view(mesh, top_poses[0])
            similarity_top1 = self._compute_similarity(reference_image, rendered_top1)
            self.visualization_data['progression'].append({
                'step_name': 'Top-1 Selection',
                'pose': top_poses[0],
                'rendered_image': rendered_top1,
                'similarity': similarity_top1,
                'score': similarity_top1
            })
        
        # æ­¥éª¤3-4: DUSt3Rä¼°è®¡ (æ ¸å¿ƒå‡ ä½•çº¦æŸ)
        print("ğŸ” æ­¥éª¤3-4: DUSt3Rå‡ ä½•çº¦æŸä¼°è®¡...")
        dust3r_pose = self._dust3r_estimation(mesh, reference_image, top_poses)
        
        # å¯è§†åŒ–ï¼šè®°å½•DUSt3Rç»“æœ
        if self.enable_visualization and dust3r_pose:
            rendered_dust3r = self.renderer.render_single_view(mesh, dust3r_pose)
            similarity_dust3r = self._compute_similarity(reference_image, rendered_dust3r)
            self.visualization_data['progression'].append({
                'step_name': 'DUSt3R Align',
                'pose': dust3r_pose,
                'rendered_image': rendered_dust3r,
                'similarity': similarity_dust3r,
                'score': similarity_dust3r
            })
        
        # æ­¥éª¤5-6: PSOæœç´¢
        print("ğŸ” æ­¥éª¤5-6: PSOç²’å­ç¾¤ä¼˜åŒ–...")
        pso_pose = self._pso_search(mesh, reference_image, dust3r_pose, top_poses)
        
        # å¯è§†åŒ–ï¼šè®°å½•PSOç»“æœ
        if self.enable_visualization:
            rendered_pso = self.renderer.render_single_view(mesh, pso_pose)
            similarity_pso = self._compute_similarity(reference_image, rendered_pso)
            self.visualization_data['progression'].append({
                'step_name': 'PSO Optimize',
                'pose': pso_pose,
                'rendered_image': rendered_pso,
                'similarity': similarity_pso,
                'score': similarity_pso
            })
        
        # æ­¥éª¤7-8: æ¢¯åº¦ä¸‹é™ç²¾åŒ–
        print("ğŸ¯ æ­¥éª¤7-8: æ¢¯åº¦ä¸‹é™ç²¾åŒ–...")
        final_pose = self._gradient_refinement(mesh, reference_image, pso_pose)
        
        # è®¡ç®—æ‰§è¡Œæ—¶é—´
        execution_time = time.time() - start_time
        
        # æ”¶é›†ç®—æ³•ç»Ÿè®¡ä¿¡æ¯
        if self.enable_visualization:
            final_rendered = self.renderer.render_single_view(mesh, final_pose)
            final_similarity = self._compute_similarity(reference_image, final_rendered)
            
            self.visualization_data['progression'].append({
                'step_name': 'Final Result',
                'pose': final_pose,
                'rendered_image': final_rendered,
                'similarity': final_similarity,
                'score': final_similarity
            })
            
            self.visualization_data['algorithm_stats'] = {
                'initial_samples': self.config['initial_samples'],
                'top_n': self.config['top_n'],
                'pso_iterations': self.config['pso_iterations'],
                'final_score': final_similarity
            }
        
        # ç”Ÿæˆå¯è§†åŒ–ç»“æœ
        if self.enable_visualization and save_visualization and self.visualizer:
            try:
                # åˆ›å»ºç»“æœå¯¹æ¯”å›¾
                final_rendered = self.renderer.render_single_view(mesh, final_pose)
                comparison_path = self.visualizer.create_result_comparison(
                    data_pair=data_pair,
                    reference_image=reference_image,
                    rendered_result=final_rendered,
                    final_pose=final_pose,
                    mesh_info=self.visualization_data['mesh_info'],
                    algorithm_stats=self.visualization_data['algorithm_stats'],
                    execution_time=execution_time
                )
                
                # åˆ›å»ºä¼˜åŒ–è¿‡ç¨‹å¯è§†åŒ–
                if self.visualization_data['progression']:
                    progression_path = self.visualizer.create_pose_progression_visualization(
                        data_pair=data_pair,
                        reference_image=reference_image,
                        progression_data=self.visualization_data['progression'],
                        final_pose=final_pose
                    )
                
                # ä¿å­˜å•ç‹¬çš„ç»“æœå›¾åƒ
                individual_paths = self.visualizer.save_individual_results(
                    data_pair=data_pair,
                    reference_image=reference_image,
                    rendered_result=final_rendered
                )
                
            except Exception as e:
                print(f"âš ï¸ å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")
        
        print("âœ… V2M4ç›¸æœºæœç´¢å®Œæˆ!")
        print(f"â±ï¸ æ€»è€—æ—¶: {execution_time:.2f}ç§’")
        
        return final_pose
    
    def _load_image(self, image_path: str) -> np.ndarray:
        """åŠ è½½å›¾åƒæ–‡ä»¶"""
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"æ— æ³•åŠ è½½å›¾åƒ: {image_path}")
        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    def _sample_sphere_poses(self) -> List[CameraPose]:
        """æ­¥éª¤1: çƒé¢ç­‰é¢ç§¯é‡‡æ ·"""
        return GeometryUtils.sample_sphere_poses(self.config['initial_samples'])
    
    def _select_top_poses(self, mesh: trimesh.Trimesh, reference_image: np.ndarray, 
                         poses: List[CameraPose]) -> List[CameraPose]:
        """æ­¥éª¤2: åŸºäºç›¸ä¼¼åº¦é€‰æ‹©top-n - ä¼˜åŒ–æ‰¹é‡æ¸²æŸ“ä»¥é¿å…nvdiffrastå¡ä½"""
        
        print(f"   æ­£åœ¨è¯„ä¼° {len(poses)} ä¸ªå€™é€‰å§¿æ€...")
        
        scores = []
        batch_size = self.config['render_batch_size']  # ä½¿ç”¨é…ç½®çš„æ‰¹é‡æ¸²æŸ“å¤§å°
        
        try:
            # å°è¯•æ‰¹é‡æ¸²æŸ“
            for i in range(0, len(poses), batch_size):
                batch_poses = poses[i:i+batch_size]
                print(f"   æ‰¹é‡æ¸²æŸ“ {i+1}-{min(i+batch_size, len(poses))}/{len(poses)}...")
                
                try:
                    # æ‰¹é‡æ¸²æŸ“è¿™ä¸€ç»„
                    rendered_images = self.renderer.render_batch_views(mesh, batch_poses)
                    
                    # è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°
                    for rendered_img in rendered_images:
                        if rendered_img is not None:
                            score = self._compute_similarity(reference_image, rendered_img)
                            scores.append(score)
                        else:
                            scores.append(float('inf'))  # æ¸²æŸ“å¤±è´¥ï¼Œç»™æœ€å·®åˆ†æ•°
                            
                except Exception as e:
                    print(f"   âš ï¸ æ‰¹é‡æ¸²æŸ“å¤±è´¥ï¼Œåˆ‡æ¢åˆ°é€ä¸ªæ¸²æŸ“: {e}")
                    # æ‰¹é‡æ¸²æŸ“å¤±è´¥ï¼Œé€ä¸ªæ¸²æŸ“è¿™ä¸€ç»„
                    for pose in batch_poses:
                        try:
                            rendered_img = self.renderer.render_single_view(mesh, pose)
                            score = self._compute_similarity(reference_image, rendered_img)
                            scores.append(score)
                        except Exception as e2:
                            print(f"   âš ï¸ å•ä¸ªæ¸²æŸ“ä¹Ÿå¤±è´¥: {e2}")
                            scores.append(float('inf'))
                
                # æ¸…ç†GPUå†…å­˜
                from .utils import cleanup_gpu_memory
                cleanup_gpu_memory()
                
        except Exception as e:
            print(f"   âŒ æ‰¹é‡æ¸²æŸ“å®Œå…¨å¤±è´¥ï¼Œä½¿ç”¨é¡ºåºæ¸²æŸ“: {e}")
            # å®Œå…¨å›é€€åˆ°é¡ºåºæ¸²æŸ“
            scores = []
            for i, pose in enumerate(poses):
                if i % 100 == 0:
                    print(f"   é¡ºåºæ¸²æŸ“è¿›åº¦: {i+1}/{len(poses)}")
                try:
                    rendered_img = self.renderer.render_single_view(mesh, pose)
                    score = self._compute_similarity(reference_image, rendered_img)
                    scores.append(score)
                except Exception as e2:
                    print(f"   âš ï¸ æ¸²æŸ“å§¿æ€ {i} å¤±è´¥: {e2}")
                    scores.append(float('inf'))
                
                # æ¯50ä¸ªå§¿æ€æ¸…ç†ä¸€æ¬¡å†…å­˜
                if i % 50 == 0:
                    from .utils import cleanup_gpu_memory
                    cleanup_gpu_memory()
        
        # é€‰æ‹©top-n
        if len(scores) != len(poses):
            print(f"   âš ï¸ åˆ†æ•°æ•°é‡({len(scores)})ä¸å§¿æ€æ•°é‡({len(poses)})ä¸åŒ¹é…")
            scores = scores[:len(poses)] + [float('inf')] * (len(poses) - len(scores))
        
        top_indices = np.argsort(scores)[:self.config['top_n']]
        selected_poses = [poses[i] for i in top_indices]
        
        print(f"   âœ… é€‰æ‹©äº† {len(selected_poses)} ä¸ªæœ€ä½³å§¿æ€")
        print(f"   æœ€ä½³åˆ†æ•°: {min(scores):.4f}")
        
        return selected_poses
    
    def _dust3r_estimation(self, mesh: trimesh.Trimesh, reference_image: np.ndarray, 
                          top_poses: List[CameraPose]) -> Optional[CameraPose]:
        """æ­¥éª¤3-4: DUSt3Rä¼°è®¡ - æ ¸å¿ƒå‡ ä½•çº¦æŸ"""
        
        # 1. æ¸²æŸ“top poses
        rendered_views = [self.renderer.render_single_view(mesh, pose) for pose in top_poses]
        
        # 2. DUSt3Ræ¨ç†
        dust3r_result = self.dust3r_helper.inference(reference_image, rendered_views)
        
        # 3. ç‚¹äº‘å¯¹é½ (ç®€åŒ–ç‰ˆ)
        best_pose = GeometryUtils.align_pointclouds_simple(
            dust3r_result.reference_pc,
            dust3r_result.rendered_pcs, 
            top_poses[:len(dust3r_result.rendered_pcs)]
        )
        
        return best_pose
    
    def _pso_search(self, mesh: trimesh.Trimesh, reference_image: np.ndarray,
                   dust3r_pose: Optional[CameraPose], top_poses: List[CameraPose]) -> CameraPose:
        """æ­¥éª¤5-6: PSOæœç´¢"""
        
        # å‡†å¤‡åˆå§‹å€™é€‰
        candidates = top_poses[:self.config['pso_particles']]
        if dust3r_pose is not None:
            candidates.append(dust3r_pose)
        
        if not candidates:
            return CameraPose(elevation=0, azimuth=0, radius=2.5)
        
        # å®šä¹‰ç›®æ ‡å‡½æ•°
        def objective(pose: CameraPose) -> float:
            rendered = self.renderer.render_single_view(mesh, pose)
            return self._compute_similarity(reference_image, rendered)
        
        # å‚æ•°è¾¹ç•Œ
        bounds = {
            'elevation': (-90, 90),
            'azimuth': (0, 360),
            'radius': (1.0, 5.0),
            'center_x': (-1.0, 1.0),
            'center_y': (-1.0, 1.0),
            'center_z': (-1.0, 1.0)
        }
        
        return self.optimizer.pso_optimize(objective, candidates, bounds)
    
    def _gradient_refinement(self, mesh: trimesh.Trimesh, reference_image: np.ndarray,
                           initial_pose: CameraPose) -> CameraPose:
        """æ­¥éª¤7-8: æ¢¯åº¦ä¸‹é™ç²¾åŒ–"""
        
        def objective(pose: CameraPose) -> float:
            rendered = self.renderer.render_single_view(mesh, pose)
            return self._compute_similarity(reference_image, rendered)
        
        return self.optimizer.gradient_descent(objective, initial_pose)
    
    def _compute_similarity(self, img1: np.ndarray, img2: np.ndarray) -> float:
        """è®¡ç®—å›¾åƒç›¸ä¼¼åº¦ - ä½¿ç”¨è¶…æ—¶ä¿æŠ¤ç‰ˆæœ¬"""
        from .utils import compute_image_similarity
        return compute_image_similarity(img1, img2, timeout=10)  # 10ç§’è¶…æ—¶ 