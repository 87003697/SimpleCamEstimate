"""
VGGTåŠ©æ‰‹æ¨¡å— - åŸºäºV2M4å®ç°
"""

import numpy as np
import torch
import torch.nn.functional as F
from dataclasses import dataclass
from typing import List, Optional
from pathlib import Path
import cv2

@dataclass
class VGGTResult:
    """VGGTæ¨ç†ç»“æœ - ä¸DUSt3Rç»“æœæ¥å£å…¼å®¹"""
    reference_pc: np.ndarray           # å‚è€ƒå›¾åƒç‚¹äº‘
    rendered_pcs: List[np.ndarray]     # æ¸²æŸ“å›¾åƒç‚¹äº‘åˆ—è¡¨
    depth_maps: List[np.ndarray]       # æ·±åº¦å›¾åˆ—è¡¨
    confidence_scores: List[float]     # ç½®ä¿¡åº¦åˆ†æ•°

class VGGTHelper:
    """VGGTåŠ©æ‰‹ç±» - åŸºäºV2M4å®ç°"""
    
    def __init__(self, device: str = "cuda"):
        self.device = device
        self.model = None
        self.is_loaded = False
        
    def load_model(self):
        """åŠ è½½VGGTæ¨¡å‹"""
        try:
            # æ£€æŸ¥æ˜¯å¦æ”¯æŒbfloat16
            dtype = torch.bfloat16 if torch.cuda.get_device_capability()[0] >= 8 else torch.float16
            self.dtype = dtype
            
            print("ğŸ”„ æ­£åœ¨åŠ è½½VGGTæ¨¡å‹...")
            
            # æ–¹æ³•1: ä½¿ç”¨PyTorchModelHubMixinç›´æ¥åŠ è½½ (V2M4çš„æ–¹å¼)
            try:
                from .vggt import VGGT
                print("   å°è¯•ä½¿ç”¨PyTorchModelHubMixinåŠ è½½...")
                self.model = VGGT.from_pretrained("facebook/VGGT-1B").to(self.device)
                print("âœ… VGGTæ¨¡å‹åŠ è½½æˆåŠŸ")
                self.is_loaded = True
                return
                
            except Exception as e1:
                print(f"âš ï¸ PyTorchModelHubMixinåŠ è½½å¤±è´¥: {e1}")
                
            # æ–¹æ³•2: æ‰‹åŠ¨åŠ è½½safetensorsæ–‡ä»¶
            try:
                import safetensors.torch
                from huggingface_hub import hf_hub_download
                
                print("   å°è¯•æ‰‹åŠ¨åŠ è½½safetensors...")
                
                # ä¸‹è½½æ¨¡å‹æ–‡ä»¶
                model_path = hf_hub_download(
                    repo_id="facebook/VGGT-1B",
                    filename="model.safetensors",
                    cache_dir="/home/zhiyuan_ma/.cache/huggingface"
                )
                
                config_path = hf_hub_download(
                    repo_id="facebook/VGGT-1B", 
                    filename="config.json",
                    cache_dir="/home/zhiyuan_ma/.cache/huggingface"
                )
                
                # è¯»å–é…ç½®
                import json
                with open(config_path, 'r') as f:
                    config = json.load(f)
                
                # åˆ›å»ºæ¨¡å‹
                from .vggt import VGGT
                self.model = VGGT(
                    img_size=config.get('img_size', 518),
                    patch_size=config.get('patch_size', 14), 
                    embed_dim=config.get('embed_dim', 1024)
                )
                
                # åŠ è½½æƒé‡
                state_dict = safetensors.torch.load_file(model_path)
                self.model.load_state_dict(state_dict)
                self.model = self.model.to(self.device)
                
                print("âœ… VGGTæ¨¡å‹æ‰‹åŠ¨åŠ è½½æˆåŠŸ")
                self.is_loaded = True
                return
                
            except Exception as e2:
                print(f"âš ï¸ æ‰‹åŠ¨åŠ è½½safetensorså¤±è´¥: {e2}")
                
            # æ–¹æ³•3: åˆ›å»ºç©ºæ¨¡å‹ç”¨äºæµ‹è¯•
            print("âš ï¸ åˆ›å»ºç©ºVGGTæ¨¡å‹ç”¨äºæµ‹è¯•...")
            from .vggt import VGGT
            self.model = VGGT().to(self.device)
            print("âœ… VGGTç©ºæ¨¡å‹åˆ›å»ºæˆåŠŸ")
            self.is_loaded = True
            
        except Exception as e:
            print(f"âŒ VGGTæ¨¡å‹åŠ è½½å®Œå…¨å¤±è´¥: {e}")
            print("âš ï¸ å°†ä½¿ç”¨å ä½ç¬¦å®ç°")
            self.is_loaded = False
        
    def _preprocess_images(self, images: List[np.ndarray]) -> torch.Tensor:
        """é¢„å¤„ç†å›¾åƒ - è½¬æ¢ä¸ºVGGTæ ¼å¼"""
        processed_images = []
        
        for img in images:
            # ç¡®ä¿å›¾åƒæ˜¯RGBæ ¼å¼
            if len(img.shape) == 3 and img.shape[2] == 3:
                # è½¬æ¢ä¸ºtensorå¹¶å½’ä¸€åŒ–åˆ°[0,1]
                if img.dtype == np.uint8:
                    img_tensor = torch.from_numpy(img).float() / 255.0
                else:
                    img_tensor = torch.from_numpy(img).float()
                
                # è°ƒæ•´ç»´åº¦é¡ºåº: HWC -> CHW
                img_tensor = img_tensor.permute(2, 0, 1)
                processed_images.append(img_tensor)
        
        # å †å æˆbatch: [S, 3, H, W]
        return torch.stack(processed_images).to(self.device)
    
    def _extract_point_clouds(self, predictions: dict, images: torch.Tensor) -> List[np.ndarray]:
        """ä»VGGTé¢„æµ‹ç»“æœä¸­æå–ç‚¹äº‘"""
        point_clouds = []
        
        # è·å–ä¸–ç•Œåæ ‡ç‚¹äº‘
        world_points = predictions["world_points"][0].detach()  # [S, H, W, 3]
        
        # æ’å€¼åˆ°åŸå›¾åƒå°ºå¯¸
        world_points = F.interpolate(
            world_points.permute(0, 3, 1, 2), 
            size=images.shape[-1], 
            mode='bilinear', 
            align_corners=False
        ).permute(0, 2, 3, 1)
        
        for i, pts in enumerate(world_points):
            # æå–æœ‰æ•ˆç‚¹äº‘ (éé»‘è‰²åƒç´ åŒºåŸŸ)
            valid_mask = images[i].permute(1, 2, 0).sum(-1) > 0
            points = pts.view(-1, 3)[valid_mask.view(-1)]
            
            # è½¬æ¢ä¸ºnumpy
            point_clouds.append(points.cpu().numpy())
        
        return point_clouds
    
    def inference(self, reference_image: np.ndarray, rendered_views: List[np.ndarray]) -> VGGTResult:
        """VGGTæ¨ç†"""
        
        if not self.is_loaded:
            self.load_model()
            
        # å¦‚æœæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¿”å›å ä½ç¬¦ç»“æœ
        if not self.is_loaded or self.model is None:
            print("âš ï¸ VGGTæ¨¡å‹æœªåŠ è½½ï¼Œä½¿ç”¨å ä½ç¬¦ç»“æœ")
            return self._create_dummy_result(reference_image, rendered_views)
        
        try:
            # 1. é¢„å¤„ç†å›¾åƒ
            all_images = [reference_image] + rendered_views
            images_tensor = self._preprocess_images(all_images)
            
            # 2. VGGTæ¨ç†
            with torch.no_grad():
                with torch.cuda.amp.autocast(dtype=self.dtype):
                    predictions = self.model(images_tensor)
            
            # 3. æå–ç‚¹äº‘
            point_clouds = self._extract_point_clouds(predictions, images_tensor)
            
            # 4. æ„å»ºç»“æœ
            reference_pc = point_clouds[0] if len(point_clouds) > 0 else np.random.rand(1000, 3).astype(np.float32)
            rendered_pcs = point_clouds[1:] if len(point_clouds) > 1 else []
            
            # æå–æ·±åº¦å›¾
            depth_maps = []
            if "depth" in predictions:
                depth_tensor = predictions["depth"][0].detach()  # [S, H, W, 1]
                for i in range(depth_tensor.shape[0]):
                    depth_map = depth_tensor[i, :, :, 0].cpu().numpy()
                    depth_maps.append(depth_map)
            
            # è®¡ç®—ç½®ä¿¡åº¦åˆ†æ•°
            confidence_scores = []
            if "world_points_conf" in predictions:
                conf_tensor = predictions["world_points_conf"][0].detach()  # [S, H, W]
                for i in range(conf_tensor.shape[0]):
                    avg_conf = conf_tensor[i].mean().item()
                    confidence_scores.append(avg_conf)
            else:
                confidence_scores = [0.8 for _ in rendered_pcs]
            
            return VGGTResult(
                reference_pc=reference_pc,
                rendered_pcs=rendered_pcs,
                depth_maps=depth_maps,
                confidence_scores=confidence_scores
            )
            
        except Exception as e:
            print(f"âŒ VGGTæ¨ç†å¤±è´¥: {e}")
            return self._create_dummy_result(reference_image, rendered_views)
    
    def _create_dummy_result(self, reference_image: np.ndarray, rendered_views: List[np.ndarray]) -> VGGTResult:
        """åˆ›å»ºå ä½ç¬¦ç»“æœ"""
        # åˆ›å»ºå ä½ç¬¦ç‚¹äº‘
        dummy_pc = np.random.rand(1000, 3).astype(np.float32)
        dummy_depth = np.random.rand(512, 512).astype(np.float32)
        
        return VGGTResult(
            reference_pc=dummy_pc,
            rendered_pcs=[dummy_pc for _ in rendered_views],
            depth_maps=[dummy_depth for _ in rendered_views],
            confidence_scores=[0.5 for _ in rendered_views]
        ) 