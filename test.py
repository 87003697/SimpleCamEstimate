#!/usr/bin/env python3
"""
V2M4ç®—æ³•ç»Ÿä¸€æµ‹è¯•è„šæœ¬
åˆå¹¶å®Œæ•´ç®—æ³•æµ‹è¯•å’Œå¯è§†åŒ–åŠŸèƒ½æµ‹è¯•ï¼Œæ”¯æŒå‚æ•°æ§åˆ¶
"""

import sys
import time
import os
import argparse
from pathlib import Path
from typing import List, Dict, Optional

import torch
import cv2

# è®¾ç½®CUDAè®¾å¤‡
def setup_cuda_device(device_id: int = 0):
    """è®¾ç½®CUDAè®¾å¤‡"""
    print(f"ğŸ”§ Setting CUDA device: {device_id}")
    os.environ['CUDA_VISIBLE_DEVICES'] = str(device_id)

def check_environment():
    """ç¯å¢ƒæ£€æŸ¥"""
    print("ğŸ”§ Environment check...")
    
    # CUDAæ£€æŸ¥
    print(f"   ğŸ¯ CUDA device setting: {os.environ.get('CUDA_VISIBLE_DEVICES', 'default')}")
    
    import torch
    if torch.cuda.is_available():
        print(f"   âœ… CUDA available, current device: {torch.cuda.current_device()}")
        print(f"   ğŸ“Š GPU name: {torch.cuda.get_device_name()}")
        print(f"   ğŸ’¾ GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
    else:
        print("   âš ï¸ CUDA not available, will use CPU")
    
    # æµ‹è¯•camera_searchåŒ…å¯¼å…¥
    import camera_search
    print("   âœ… camera_search package imported successfully")
    
    # æ£€æŸ¥å¿…éœ€ä¾èµ–
    import nvdiffrast
    print("   âœ… nvdiffrast available (required)")
    
    import kiui
    print("   âœ… kiui available (required)")
    
    # æ£€æŸ¥å¯è§†åŒ–ä¾èµ–
    import matplotlib
    print("   âœ… matplotlib available")
    
    # æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
    from camera_search import validate_data_integrity
    validation = validate_data_integrity()
    print(f"   ğŸ“Š Data integrity: {validation['data_completeness']:.1f}%")
    print(f"   ğŸ“ Valid data pairs: {validation['valid_data_pairs']}")
    
    if validation['valid_data_pairs'] == 0:
        print("   âŒ No valid data pairs found, cannot run tests")
        return False
    
    return True

def test_visualization_components():
    """æµ‹è¯•å¯è§†åŒ–ç»„ä»¶"""
    print("ğŸ¨ Testing visualization components...")
    
    from camera_search.visualization import V2M4Visualizer
    from camera_search import DataPair, CameraPose
    import numpy as np
    import cv2
    
    # åˆ›å»ºå¯è§†åŒ–å™¨
    visualizer = V2M4Visualizer(output_dir="outputs/test_visualization")
    print("   âœ… Visualizer created successfully")
    
    # æµ‹è¯•åœºæ™¯
    test_scene = "dancing_spiderman"
    data_pair = DataPair.from_scene_name(test_scene)
    
    if not data_pair.exists():
        print("   âš ï¸ Test scene does not exist, skipping component test")
        return True
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    reference_image = np.random.rand(512, 512, 3) * 255
    reference_image = reference_image.astype(np.uint8)
    rendered_result = np.random.rand(512, 512, 3) * 255
    rendered_result = rendered_result.astype(np.uint8)
    test_pose = CameraPose(elevation=30, azimuth=45, radius=3.0)
    
    mesh_info = {
        'vertices': 1000,
        'faces': 2000,
        'bounds': [[-1, -1, -1], [1, 1, 1]],
        'center': [0, 0, 0],
        'scale': 2.0
    }
    
    algorithm_stats = {
        'initial_samples': 512,
        'top_n': 8,
        'pso_iterations': 50,
        'final_score': 0.85
    }
    
    # æµ‹è¯•ç»“æœå¯¹æ¯”å›¾
    comparison_path = visualizer.create_result_comparison(
        data_pair=data_pair,
        reference_image=reference_image,
        rendered_result=rendered_result,
        final_pose=test_pose,
        mesh_info=mesh_info,
        algorithm_stats=algorithm_stats,
        execution_time=120.5
    )
    
    print(f"   âœ… Result comparison chart: {Path(comparison_path).name}")
    
    # æµ‹è¯•ä¼˜åŒ–è¿‡ç¨‹å¯è§†åŒ–
    progression_data = [
        {
            'step_name': 'Initial Sampling',
            'pose': CameraPose(elevation=20, azimuth=30, radius=3.5),
            'rendered_image': np.random.rand(512, 512, 3) * 255,
            'score': 0.6
        },
        {
            'step_name': 'PSO Optimization',
            'pose': CameraPose(elevation=25, azimuth=40, radius=3.2),
            'rendered_image': np.random.rand(512, 512, 3) * 255,
            'score': 0.75
        },
        {
            'step_name': 'Final Result',
            'pose': test_pose,
            'rendered_image': rendered_result,
            'score': 0.85
        }
    ]
    
    # ç¡®ä¿progression_dataä¸­çš„rendered_imageä¹Ÿæ˜¯numpyæ•°ç»„
    for step_data in progression_data:
        if 'rendered_image' in step_data:
            step_data['rendered_image'] = step_data['rendered_image'].astype(np.uint8)
    
    progression_path = visualizer.create_pose_progression_visualization(
        data_pair=data_pair,
        reference_image=reference_image,
        progression_data=progression_data,
        final_pose=test_pose
    )
    
    print(f"   âœ… Optimization process chart: {Path(progression_path).name}")
    
    return True

def run_single_scene_test(scene_name: str, use_model: str = 'none', enable_visualization: bool = True, 
                          max_batch_size: int = 8) -> bool:
    """è¿è¡Œå•åœºæ™¯æµ‹è¯•"""
    model_name = use_model.upper() if use_model != 'none' else 'None (Skip Model Step)'
    print(f"ğŸ¬ Testing scene: {scene_name} (using {model_name})")
    print(f"   ğŸ”§ Max batch size: {max_batch_size}")
    
    from camera_search import DataPair, CleanV2M4CameraSearch
    
    # åˆ›å»ºæ•°æ®å¯¹
    data_pair = DataPair.from_scene_name(scene_name)
    if not data_pair.exists():
        print(f"   âŒ Scene data does not exist: {scene_name}")
        return False
    
    # åˆ›å»ºæœç´¢å™¨
    searcher = CleanV2M4CameraSearch(
        dust3r_model_path="/data0/zhiyuan/code/MeshSeriesGen/pretrained_weights/dust3r/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth",
        device="cuda",
        enable_visualization=enable_visualization
    )
    
    # é…ç½®ä½¿ç”¨çš„æ¨¡å‹
    if use_model == 'dust3r':
        searcher.config['use_dust3r'] = True
        searcher.config['model_name'] = 'dust3r'
        print(f"   ğŸ”„ Using DUSt3R mode")
    else:  # none
        searcher.config['skip_model_step'] = True
        searcher.config['model_name'] = 'none'
    
    # è®¾ç½®æ‰¹é‡æ¸²æŸ“å¤§å°
    searcher.config['max_batch_size'] = max_batch_size
    
    # è¿è¡Œç®—æ³•
    import time
    start_time = time.time()
    
    best_pose = searcher.search_camera_pose(data_pair, save_visualization=enable_visualization)
    elapsed = time.time() - start_time
    
    if best_pose is not None:
        print(f"   âœ… Success! Pose: elevation={best_pose.elevation:.1f}Â°, azimuth={best_pose.azimuth:.1f}Â°, distance={best_pose.radius:.2f}")
        print(f"   â±ï¸ Execution time: {elapsed:.1f} seconds")
        print(f"   ğŸ¤– Model: {model_name}")
        
        # ç»Ÿè®¡å¯è§†åŒ–æ–‡ä»¶
        if enable_visualization:
            output_dir = Path("outputs/visualization")
            viz_files = list(output_dir.glob("*"))
            print(f"   ğŸ“Š Visualization files: {len(viz_files)}")
        
        return True
    else:
        print(f"   âŒ Algorithm execution failed")
        return False

def run_batch_test(num_scenes: int = 5, use_model: str = 'none', 
                  enable_visualization: bool = True, create_batch_summary: bool = True,
                  max_batch_size: int = 8) -> Dict:
    """è¿è¡Œæ‰¹é‡æµ‹è¯•"""
    model_name = use_model.upper() if use_model != 'none' else 'None (Skip Model Step)'
    
    print(f"\nğŸ”„ Batch testing {num_scenes} scenes (using {model_name})...")
    print(f"   ğŸ¨ Visualization: {'enabled' if enable_visualization else 'disabled'}")
    print(f"   ğŸ“‹ Batch summary: {'enabled' if create_batch_summary else 'disabled'}")
    print(f"   ğŸ”§ Max batch size: {max_batch_size}")
    
    from camera_search import DataManager, CleanV2M4CameraSearch
    
    # è·å–å¯ç”¨åœºæ™¯
    data_manager = DataManager()
    available_scenes = data_manager.discover_data_pairs()
    
    if not available_scenes:
        print(f"   âŒ No scenes found")
        return {'success': False, 'results': {}}
    
    print(f"   ğŸ“ Found scenes: {len(available_scenes)}")
    
    # é€‰æ‹©æµ‹è¯•åœºæ™¯
    test_scenes = available_scenes[:num_scenes]
    print(f"   ğŸ¯ Test scenes: {[s.scene_name for s in test_scenes]}")
    
    # åˆ›å»ºæœç´¢å™¨
    searcher = CleanV2M4CameraSearch(
        dust3r_model_path="/data0/zhiyuan/code/MeshSeriesGen/pretrained_weights/dust3r/DUSt3R_ViTLarge_BaseDecoder_512_dpt.pth",
        device="cuda",
        enable_visualization=enable_visualization
    )
    
    # é…ç½®ä½¿ç”¨çš„æ¨¡å‹
    if use_model == 'dust3r':
        searcher.config['use_dust3r'] = True
        searcher.config['model_name'] = 'dust3r'
    else:  # none
        searcher.config['skip_model_step'] = True
        searcher.config['model_name'] = 'none'
    
    # è®¾ç½®æ‰¹é‡æ¸²æŸ“å¤§å°
    searcher.config['max_batch_size'] = max_batch_size
    
    # æ‰¹é‡å¤„ç†
    results = {}
    execution_times = {}
    successful = 0
    total_elapsed = 0
    
    for i, data_pair in enumerate(test_scenes):
        print(f"\n   [{i+1}/{len(test_scenes)}] Processing scene: {data_pair.scene_name}")
        
        import time
        start_time = time.time()
        
        best_pose = searcher.search_camera_pose(data_pair, save_visualization=enable_visualization)
        elapsed = time.time() - start_time
        
        if best_pose is not None:
            results[data_pair.scene_name] = best_pose
            execution_times[data_pair.scene_name] = elapsed
            successful += 1
            total_elapsed += elapsed
        else:
            results[data_pair.scene_name] = None
    
    # ç”Ÿæˆæ‰¹é‡æ€»ç»“
    if create_batch_summary and enable_visualization:
        from camera_search import create_visualization_summary
        summary_path = create_visualization_summary(results, execution_times)
        print(f"   ğŸ“‹ Batch summary: {Path(summary_path).name}")
    
    # ç»Ÿè®¡ç»“æœ
    success_rate = (successful / len(test_scenes)) * 100
    avg_time = total_elapsed / successful if successful > 0 else 0
    
    print(f"\n   âœ… Batch processing completed!")
    print(f"   âœ… Success rate: {successful}/{len(test_scenes)} ({success_rate:.1f}%)")
    print(f"   â±ï¸ Total execution time: {total_elapsed:.1f} seconds")
    print(f"   â±ï¸ Average execution time: {avg_time:.1f} seconds/scene")
    
    # æ˜¾ç¤ºç»“æœæ‘˜è¦
    print(f"\n   ğŸ“Š Results summary:")
    for scene, pose in results.items():
        if pose is not None:
            print(f"   {scene}: elevation={pose.elevation:.1f}Â°, azimuth={pose.azimuth:.1f}Â°")
        else:
            print(f"   {scene}: failed")
    
    return {
        'success': True,
        'results': results,
        'execution_times': execution_times,
        'success_rate': success_rate,
        'total_time': total_elapsed,
        'average_time': avg_time
    }

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='V2M4 Camera Search Algorithm Test')
    parser.add_argument('--scenes', type=int, default=1, help='Number of scenes to test')
    parser.add_argument('--single-scene', type=str, help='Test single scene by name')
    parser.add_argument('--use-model', type=str, choices=['dust3r', 'none'], default='none', 
                       help='Model to use for geometric constraint estimation (default: none)')
    parser.add_argument('--cuda-device', type=int, default=0, help='CUDA device ID')
    parser.add_argument('--no-visualization', action='store_true', help='Disable visualization')
    parser.add_argument('--no-batch-summary', action='store_true', help='Disable batch summary')
    parser.add_argument('--max-batch-size', type=int, default=8, 
                       help='Maximum batch size for rendering (default: 8, larger values use more GPU memory)')
    
    args = parser.parse_args()
    
    # è®¾ç½®CUDAè®¾å¤‡
    setup_cuda_device(args.cuda_device)
    
    print("ğŸš€ V2M4 Algorithm Unified Test")
    print("=" * 50)
    
    # ç¯å¢ƒæ£€æŸ¥
    if not check_environment():
        print("âŒ Environment check failed, exiting test")
        sys.exit(1)
    
    # æµ‹è¯•å¯è§†åŒ–ç»„ä»¶
    if not args.no_visualization:
        if not test_visualization_components():
            print("âš ï¸ Visualization component test failed, but continuing...")
    
    # è¿è¡Œæµ‹è¯•
    passed_tests = 0
    total_tests = 0
    
    if args.single_scene:
        print(f"\nğŸ¯ Single scene test mode: {args.single_scene}")
        total_tests = 1
        
        success = run_single_scene_test(
            scene_name=args.single_scene,
            use_model=args.use_model,
            enable_visualization=not args.no_visualization,
            max_batch_size=args.max_batch_size
        )
        
        if success:
            passed_tests = 1
    else:
        # æ‰¹é‡æµ‹è¯•
        total_tests = 1
        
        batch_result = run_batch_test(
            num_scenes=args.scenes,
            use_model=args.use_model,
            enable_visualization=not args.no_visualization,
            create_batch_summary=not args.no_batch_summary,
            max_batch_size=args.max_batch_size
        )
        
        if batch_result['success']:
            passed_tests = 1
    
    # è¾“å‡ºæœ€ç»ˆç»“æœ
    print("\n" + "=" * 50)
    if passed_tests == total_tests:
        print(f"ğŸ‰ All tests passed! ({passed_tests}/{total_tests})")
        print("ğŸ“Š V2M4 algorithm is working normally!")
        
        # ç»Ÿè®¡å¯è§†åŒ–æ–‡ä»¶
        if not args.no_visualization:
            output_dir = Path("outputs/visualization")
            if output_dir.exists():
                viz_files = list(output_dir.glob("*"))
                print(f"\nğŸ“ Visualization files: {len(viz_files)}")
                print(f"   Location: {output_dir}")
        
        print(f"\nğŸ’¡ Usage examples:")
        print(f"   python test.py --scenes 5                    # Test 5 scenes (no model)")
        print(f"   python test.py --single-scene 'dancing_spiderman'  # Test single scene (no model)")
        print(f"   python test.py --single-scene 'dancing_spiderman' --use-model dust3r  # Use DUSt3R")
        print(f"   python test.py --no-visualization            # Disable visualization")
        print(f"   python test.py --scenes 25                   # Test all scenes (no model)")
        print(f"   python test.py --scenes 5 --use-model dust3r # Use DUSt3R batch test")
        print(f"   python test.py --max-batch-size 16           # Use larger batch size (more GPU memory)")
        print(f"   python test.py --max-batch-size 4            # Use smaller batch size (less GPU memory)")
        
    else:
        print(f"âš ï¸ Some tests failed: {passed_tests}/{total_tests}")
        print("Please check error messages and fix issues")

if __name__ == "__main__":
    main()
