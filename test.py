#!/usr/bin/env python3
"""
V2M4ç®—æ³•ç»Ÿä¸€æµ‹è¯•è„šæœ¬
åˆå¹¶å®Œæ•´ç®—æ³•æµ‹è¯•å’Œå¯è§†åŒ–åŠŸèƒ½æµ‹è¯•ï¼Œæ”¯æŒå‚æ•°æ§åˆ¶
"""

import sys
import time
import os
import argparse
from pathlib import Path
from typing import List, Dict, Optional

import torch
import cv2

# å¯¼å…¥é…ç½®
from config import (
    setup_environment, 
    get_dust3r_paths, 
    get_stablenormal_config,
    print_config_status,
    DUST3R_MODEL_PATH
)

# å¯¼å…¥GPUæ€§èƒ½ç›‘æ§
from camera_search.gpu_profiler import enable_profiling, disable_profiling, print_profiling_summary

# è®¾ç½®CUDAè®¾å¤‡
def setup_cuda_device(device_id: int = 0):
    """è®¾ç½®CUDAè®¾å¤‡"""
    print(f"ğŸ”§ Setting CUDA device: {device_id}")
    os.environ['CUDA_VISIBLE_DEVICES'] = str(device_id)
    # ä¹Ÿæ›´æ–°é…ç½®
    setup_environment()

def check_environment():
    """ç¯å¢ƒæ£€æŸ¥"""
    print("ğŸ”§ Environment check...")
    
    # æ‰“å°é…ç½®çŠ¶æ€
    print_config_status()
    
    # CUDAæ£€æŸ¥
    print(f"   ğŸ¯ CUDA device setting: {os.environ.get('CUDA_VISIBLE_DEVICES', 'default')}")
    
    import torch
    if torch.cuda.is_available():
        print(f"   âœ… CUDA available, current device: {torch.cuda.current_device()}")
        print(f"   ğŸ“Š GPU name: {torch.cuda.get_device_name()}")
        print(f"   ğŸ’¾ GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
    else:
        print("   âš ï¸ CUDA not available, will use CPU")
    
    # æµ‹è¯•camera_searchåŒ…å¯¼å…¥
    import camera_search
    print("   âœ… camera_search package imported successfully")
    
    # æ£€æŸ¥å¿…éœ€ä¾èµ–
    import nvdiffrast
    print("   âœ… nvdiffrast available (required)")
    
    import kiui
    print("   âœ… kiui available (required)")
    
    # æ£€æŸ¥å¯è§†åŒ–ä¾èµ–
    import matplotlib
    print("   âœ… matplotlib available")
    
    # æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
    from camera_search import validate_data_integrity
    validation = validate_data_integrity()
    print(f"   ğŸ“Š Data integrity: {validation['data_completeness']:.1f}%")
    print(f"   ğŸ“ Valid data pairs: {validation['valid_data_pairs']}")
    
    if validation['valid_data_pairs'] == 0:
        print("   âŒ No valid data pairs found, cannot run tests")
        return False
    
    return True

def run_single_scene_test(scene_name: str, use_model: str = 'none', enable_visualization: bool = True, 
                          max_batch_size: int = 8, render_mode: str = 'lambertian', use_normal: bool = False) -> bool:
    """è¿è¡Œå•åœºæ™¯æµ‹è¯•"""
    model_name = use_model.upper() if use_model != 'none' else 'None (Skip Model Step)'
    print(f"ğŸ¬ Testing scene: {scene_name} (using {model_name})")
    print(f"   ğŸ”§ Max batch size: {max_batch_size}")
    print(f"   ğŸ¨ Render mode: {render_mode}")
    if use_normal:
        print(f"   ğŸ¨ Using normal predictor mode")
    
    from camera_search import DataPair, CleanV2M4CameraSearch
    
    # åˆ›å»ºæ•°æ®å¯¹
    data_pair = DataPair.from_scene_name(scene_name)
    if not data_pair.exists():
        print(f"   âŒ Scene data does not exist: {scene_name}")
        return False
    
    # åˆ›å»ºæœç´¢å™¨ - ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è·¯å¾„
    searcher = CleanV2M4CameraSearch(
        dust3r_model_path=DUST3R_MODEL_PATH,  # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è·¯å¾„
        device="cuda",
        enable_visualization=enable_visualization
    )
    
    # é…ç½®ä½¿ç”¨çš„æ¨¡å‹
    if use_model == 'dust3r':
        searcher.config['use_dust3r'] = True
        searcher.config['model_name'] = 'dust3r'
        print(f"   ğŸ”„ Using DUSt3R mode")
    else:  # none
        searcher.config['skip_model_step'] = True
        searcher.config['model_name'] = 'none'
    
    # è®¾ç½®æ¸²æŸ“é…ç½®
    searcher.config['max_batch_size'] = max_batch_size
    searcher.config['render_mode'] = render_mode
    
    # è¿è¡Œç®—æ³•
    import time
    start_time = time.time()
    
    best_pose = searcher.search_camera_pose(data_pair, save_visualization=enable_visualization, use_normal=use_normal)
    elapsed = time.time() - start_time
    
    if best_pose is not None:
        print(f"   âœ… Algorithm completed in {elapsed:.1f} seconds")
        print(f"   ğŸ“Š Final pose: {best_pose}")
        return True
    else:
        print(f"   âŒ Algorithm failed")
        return False

def run_batch_test(num_scenes: int = 5, use_model: str = 'none', 
                  enable_visualization: bool = True, create_batch_summary: bool = True,
                  max_batch_size: int = 8, render_mode: str = 'lambertian', use_normal: bool = False) -> Dict:
    """è¿è¡Œæ‰¹é‡æµ‹è¯•"""
    model_name = use_model.upper() if use_model != 'none' else 'None (Skip Model Step)'
    
    print(f"\nğŸ”„ Batch testing {num_scenes} scenes (using {model_name})...")
    print(f"   ğŸ¨ Visualization: {'enabled' if enable_visualization else 'disabled'}")
    print(f"   ğŸ“‹ Batch summary: {'enabled' if create_batch_summary else 'disabled'}")
    print(f"   ğŸ”§ Max batch size: {max_batch_size}")
    print(f"   ğŸ¨ Render mode: {render_mode}")
    if use_normal:
        print(f"   ğŸ¨ Using normal predictor mode")
    
    from camera_search import DataManager, CleanV2M4CameraSearch
    
    # è·å–å¯ç”¨åœºæ™¯
    data_manager = DataManager()
    available_scenes = data_manager.discover_data_pairs()
    
    if not available_scenes:
        print(f"   âŒ No scenes found")
        return {'success': False, 'results': {}}
    
    print(f"   ğŸ“ Found scenes: {len(available_scenes)}")
    
    # é€‰æ‹©æµ‹è¯•åœºæ™¯
    test_scenes = available_scenes[:num_scenes]
    print(f"   ğŸ¯ Test scenes: {[s.scene_name for s in test_scenes]}")
    
    # åˆ›å»ºæœç´¢å™¨ - ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è·¯å¾„
    searcher = CleanV2M4CameraSearch(
        dust3r_model_path=DUST3R_MODEL_PATH,  # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è·¯å¾„
        device="cuda",
        enable_visualization=enable_visualization
    )
    
    # é…ç½®ä½¿ç”¨çš„æ¨¡å‹
    if use_model == 'dust3r':
        searcher.config['use_dust3r'] = True
        searcher.config['model_name'] = 'dust3r'
    else:  # none
        searcher.config['skip_model_step'] = True
        searcher.config['model_name'] = 'none'
    
    # è®¾ç½®æ¸²æŸ“é…ç½®
    searcher.config['max_batch_size'] = max_batch_size
    searcher.config['render_mode'] = render_mode
    
    # è¿è¡Œæ‰¹é‡æµ‹è¯•
    results = {}
    execution_times = []
    
    total_start_time = time.time()
    
    for i, data_pair in enumerate(test_scenes):
        print(f"\nğŸ”„ Testing scene {i+1}/{len(test_scenes)}: {data_pair.scene_name}")
        
        start_time = time.time()
        try:
            best_pose = searcher.search_camera_pose(data_pair, save_visualization=enable_visualization, use_normal=use_normal)
            elapsed = time.time() - start_time
            
            if best_pose is not None:
                results[data_pair.scene_name] = {
                    'success': True,
                    'pose': best_pose,
                    'execution_time': elapsed
                }
                print(f"   âœ… Completed in {elapsed:.1f}s")
            else:
                results[data_pair.scene_name] = {
                    'success': False,
                    'pose': None,
                    'execution_time': elapsed
                }
                print(f"   âŒ Failed in {elapsed:.1f}s")
            
            execution_times.append(elapsed)
            
        except Exception as e:
            elapsed = time.time() - start_time
            results[data_pair.scene_name] = {
                'success': False,
                'pose': None,
                'execution_time': elapsed,
                'error': str(e)
            }
            execution_times.append(elapsed)
            print(f"   âŒ Error: {e}")
    
    total_elapsed = time.time() - total_start_time
    
    # ç»Ÿè®¡ç»“æœ
    success_count = sum(1 for r in results.values() if r['success'])
    success_rate = success_count / len(results) * 100
    avg_time = sum(execution_times) / len(execution_times) if execution_times else 0
    
    print(f"\nğŸ“Š Batch test results:")
    print(f"   âœ… Success rate: {success_rate:.1f}% ({success_count}/{len(results)})")
    print(f"   â±ï¸ Average time: {avg_time:.1f}s")
    print(f"   ğŸ•’ Total time: {total_elapsed:.1f}s")
    
    return {
        'success': True,
        'results': results,
        'execution_times': execution_times,
        'success_rate': success_rate,
        'total_time': total_elapsed,
        'average_time': avg_time
    }

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='V2M4 Camera Search Algorithm Test')
    parser.add_argument('--scenes', type=int, default=1, help='Number of scenes to test')
    parser.add_argument('--single-scene', type=str, help='Test single scene by name')
    parser.add_argument('--use-model', type=str, choices=['dust3r', 'none'], default='none', 
                       help='Model to use for geometric constraint estimation (default: none)')
    parser.add_argument('--cuda-device', type=int, default=0, help='CUDA device ID')
    parser.add_argument('--no-visualization', action='store_true', help='Disable visualization')
    parser.add_argument('--no-batch-summary', action='store_true', help='Disable batch summary')
    parser.add_argument('--max-batch-size', type=int, default=8, 
                       help='Maximum batch size for rendering (default: 8, larger values use more GPU memory)')
    parser.add_argument('--render-mode', type=str, choices=['lambertian', 'normal', 'textured', 'depth'], default='lambertian',
                       help='Render mode for rendering the 3D model (default: lambertian)')
    parser.add_argument('--use-normal', action='store_true', 
                       help='Use normal predictor to convert input image to normal map before matching')
    parser.add_argument('--profile', action='store_true', 
                       help='Enable GPU performance profiling')
    
    args = parser.parse_args()
    
    # å¯ç”¨GPUæ€§èƒ½ç›‘æ§
    if args.profile:
        print("ğŸ” GPU Performance profiling enabled")
        enable_profiling()
    
    # è®¾ç½®CUDAè®¾å¤‡
    setup_cuda_device(args.cuda_device)
    
    print("ğŸš€ V2M4 Algorithm Unified Test")
    print("=" * 50)
    
    # ç¯å¢ƒæ£€æŸ¥
    if not check_environment():
        print("âŒ Environment check failed, exiting test")
        sys.exit(1)
    
    # è¿è¡Œæµ‹è¯•
    passed_tests = 0
    total_tests = 0
    
    if args.single_scene:
        # å•åœºæ™¯æµ‹è¯•
        total_tests = 1
        if run_single_scene_test(
            args.single_scene, 
            args.use_model, 
            not args.no_visualization,
            args.max_batch_size,
            args.render_mode,
            args.use_normal
        ):
            passed_tests = 1
    else:
        # æ‰¹é‡æµ‹è¯•
        total_tests = 1
        batch_results = run_batch_test(
            args.scenes, 
            args.use_model, 
            not args.no_visualization,
            not args.no_batch_summary,
            args.max_batch_size,
            args.render_mode,
            args.use_normal
        )
        if batch_results['success']:
            passed_tests = 1
    
    # æ˜¾ç¤ºæ€§èƒ½ç›‘æ§æ‘˜è¦
    if args.profile:
        print_profiling_summary()
        disable_profiling()
    
    print("\n" + "=" * 50)
    print(f"ğŸ‰ All tests passed! ({passed_tests}/{total_tests})")
    print("ğŸ“Š V2M4 algorithm is working normally!")
    
    # æ˜¾ç¤ºå¯è§†åŒ–æ–‡ä»¶ä¿¡æ¯
    if not args.no_visualization:
        visualization_dir = Path("outputs/visualization")
        if visualization_dir.exists():
            viz_files = list(visualization_dir.glob("*"))
            print(f"\nğŸ“ Visualization files: {len(viz_files)}")
            print(f"   Location: {visualization_dir}")
    
    # æ˜¾ç¤ºç”¨æ³•ç¤ºä¾‹
    print("\nğŸ’¡ Usage examples:")
    print("   python test.py --scenes 5                    # Test 5 scenes (no model)")
    print("   python test.py --single-scene 'dancing_spiderman'  # Test single scene (no model)")
    print("   python test.py --single-scene 'dancing_spiderman' --use-model dust3r  # Use DUSt3R")
    print("   python test.py --no-visualization            # Disable visualization")
    print("   python test.py --scenes 25                   # Test all scenes (no model)")
    print("   python test.py --scenes 5 --use-model dust3r # Use DUSt3R batch test")
    print("   python test.py --max-batch-size 16           # Use larger batch size (more GPU memory)")
    print("   python test.py --max-batch-size 4            # Use smaller batch size (less GPU memory)")
    print("   python test.py --render-mode normal          # Use normal rendering mode")
    print("   python test.py --render-mode textured        # Use textured rendering mode")
    print("   python test.py --render-mode depth           # Use depth rendering mode")
    print("   python test.py --use-normal                  # Use normal predictor mode")
    print("   python test.py --use-normal --render-mode normal  # Use normal predictor + normal rendering")
    print("   python test.py --single-scene 'dancing_spiderman' --profile  # Enable GPU profiling")
    print("   python test.py --scenes 5 --profile          # Enable GPU profiling for batch test")

if __name__ == "__main__":
    main()
